const MLService = require('../../domain/services/mlService');
const AnalyticsService = require('../../domain/services/analyticsService');
const KnowledgeBaseRepository = require('../../domain/repositories/knowledgeBaseRepository');
const CourseRepository = require('../../domain/repositories/courseRepository');
const CareerRepository = require('../../domain/repositories/careerRepository');
// âœ… FASE II: Importar el nuevo servicio de chat para manejar el historial.
const ChatService = require('../../domain/services/chatService');

class ChatController {
    constructor(chatService, analyticsService) {
        console.log('ğŸ”„ Inicializando ChatController...');
        this.mlService = MLService;
        this.analyticsService = analyticsService;
        this.knowledgeBaseRepo = new KnowledgeBaseRepository();
        this.chatService = chatService;
        console.log('âœ… ChatController inicializado correctamente');

        // Bindeo explÃ­cito para mantener el contexto
        this.processMessage = this.processMessage.bind(this);
        this.trainModel = this.trainModel.bind(this);
        // âœ… FASE II: Bindeo de los nuevos mÃ©todos para el historial.
        this.getUserConversations = this.getUserConversations.bind(this);
        this.getConversationMessages = this.getConversationMessages.bind(this);
        this.updateConversationTitle = this.updateConversationTitle.bind(this); // âœ… MEJORA
        this.deleteConversation = this.deleteConversation.bind(this); // âœ… MEJORA
    }

    /**
     * Procesa un mensaje del usuario, lo clasifica, obtiene una respuesta de la IA
     * y guarda toda la interacciÃ³n en la base de datos.
     */
    async processMessage(req, res) {
        try {
            console.log('ğŸ’¬ ChatController.processMessage: this context:', {
                hasMlService: !!this.mlService,
                hasAnalyticsService: !!this.analyticsService,
            });

            // âœ… FASE II: Extraer datos del request.
            const { message } = req.body;
            let { conversationId } = req.body; // 'let' porque puede ser creado.
            const userId = req.user.id; // Obtenido del token JWT.

            if (!message || message.trim() === '') {
                return res.status(400).json({ error: 'El mensaje no puede estar vacÃ­o' });
            }

            console.log('ğŸ’¬ Procesando mensaje:', message);

            if (!this.mlService) {
                console.error('âŒ ERROR CRÃTICO: mlService no estÃ¡ disponible');
                throw new Error('Servicio ML no disponible');
            }

            if (!this.analyticsService) {
                console.error('âŒ ERROR CRÃTICO: analyticsService no estÃ¡ disponible');
            }

            // --- âœ… FASE II: LÃ“GICA DE PERSISTENCIA DEL CHAT ---
            // 1. Si es un mensaje nuevo, crear la conversaciÃ³n en la BD.
            if (!conversationId) {
                const title = message.substring(0, 50) + (message.length > 50 ? '...' : '');
                const newConversation = await this.chatService.chatRepository.createConversation(userId, title);
                conversationId = newConversation.id;
            }

            // 2. Guardar el mensaje del usuario en la BD.
            await this.chatService.chatRepository.addMessage(conversationId, 'user', message);

            // 3. Obtener el historial COMPLETO desde la BD para dar contexto a la IA.
            const conversationHistory = await this.chatService.chatRepository.getMessagesByConversationId(conversationId, userId);

            // --- LÃ“GICA ORIGINAL DE IA (MODIFICADA PARA USAR EL HISTORIAL DE LA BD) ---
            let classification;
            try {
                const loadedKBSet = await this.knowledgeBaseRepo.load();

                console.log('ğŸ¤– Intentando generar respuesta con LLM...');
                // Se pasa el historial obtenido de la base de datos.
                classification = await this.mlService.classifyIntent(message, conversationHistory, {
                    knowledgeBaseRepo: this.knowledgeBaseRepo,
                    courseRepo: new CourseRepository(),
                    careerRepo: new CareerRepository(),
                    knowledgeBaseSet: loadedKBSet
                });
                console.log('âœ… Respuesta de LLM recibida:', classification);
            } catch (mlError) {
                console.error('âŒ ERROR CRÃTICO llamando a mlService:', mlError);
                // Si el servicio de ML falla por completo, devolvemos un error 500.
                return res.status(500).json({ error: 'El servicio de IA no estÃ¡ disponible' });
            }

            const response = await this.enrichResponse(message, classification);

            // 4. Guardar la respuesta del bot en la BD.
            const botMessage = await this.chatService.chatRepository.addMessage(conversationId, 'bot', response.respuesta);

            // 5. REGISTRAR EN ANALYTICS (LÃ³gica original)
            if (this.analyticsService) {
                // âœ… REFACTOR: Usar clasificaciÃ³n centralizada basada en CONTENIDO
                const isEducational = this.analyticsService.isQueryEducational(message);

                await this.analyticsService.recordSearchWithIntent(
                    message,
                    [], // No hay "resultados" directos en una conversaciÃ³n de chat
                    isEducational,
                    userId, 'chatbot' // âœ… MEJORA: Especificar que la fuente es el chatbot.
                );
            }

            console.log('âœ… Respuesta generada exitosamente');

            res.json({
                ...response,
                // Devolver siempre el ID de la conversaciÃ³n para que el frontend pueda continuarla.
                conversationId: conversationId,
                // âœ… NUEVO: Devolver el ID del mensaje del bot para el feedback.
                messageId: botMessage.id,
                timestamp: new Date().toISOString()
            });

        } catch (error) {
            console.error('âŒ Error en ChatController.processMessage:', error);
            res.status(500).json({
                error: 'Error al procesar el mensaje',
                respuesta: 'Lo siento, hubo un error al procesar tu mensaje. Por favor, intenta nuevamente.'
            });
        }
    }

    /**
     * Obtiene la lista de todas las conversaciones de un usuario.
     */
    async getUserConversations(req, res) {
        try {
            const userId = req.user.id;
            const conversations = await this.chatService.getConversations(userId);
            res.json(conversations);
        } catch (error) {
            console.error('âŒ Error obteniendo conversaciones:', error);
            res.status(500).json({ error: 'Error al obtener las conversaciones.' });
        }
    }

    /**
     * Obtiene todos los mensajes de una conversaciÃ³n especÃ­fica.
     */
    async getConversationMessages(req, res) {
        try {
            const userId = req.user.id;
            const conversationId = parseInt(req.params.id, 10);
            const messages = await this.chatService.getMessages(conversationId, userId);
            res.json(messages);
        } catch (error) {
            console.error('âŒ Error obteniendo mensajes:', error);
            res.status(500).json({ error: 'Error al obtener los mensajes de la conversaciÃ³n.' });
        }
    }

    /**
     * Actualiza el tÃ­tulo de una conversaciÃ³n.
     */
    async updateConversationTitle(req, res) {
        try {
            const userId = req.user.id;
            const conversationId = parseInt(req.params.id, 10);
            const { title } = req.body;

            if (!title || title.trim() === '') {
                return res.status(400).json({ error: 'El tÃ­tulo no puede estar vacÃ­o.' });
            }

            const updatedConversation = await this.chatService.updateConversationTitle(conversationId, title, userId);
            res.json(updatedConversation);
        } catch (error) {
            console.error('âŒ Error actualizando tÃ­tulo de conversaciÃ³n:', error);
            res.status(500).json({ error: 'Error al actualizar el tÃ­tulo.' });
        }
    }

    /**
     * Elimina una conversaciÃ³n.
     */
    async deleteConversation(req, res) {
        try {
            const userId = req.user.id;
            const conversationId = parseInt(req.params.id, 10);

            const wasDeleted = await this.chatService.deleteConversation(conversationId, userId);

            if (wasDeleted) {
                res.status(204).send(); // No Content
            } else {
                // Esto puede pasar si el usuario intenta borrar un chat que no es suyo o no existe.
                res.status(404).json({ error: 'ConversaciÃ³n no encontrada o no tienes permiso para eliminarla.' });
            }
        } catch (error) {
            console.error('âŒ Error eliminando conversaciÃ³n:', error);
            res.status(500).json({ error: 'Error al eliminar la conversaciÃ³n.' });
        }
    }

    async enrichResponse(userMessage, llmResult) {
        // La respuesta principal ya viene del LLM.
        // Esta funciÃ³n ahora solo aÃ±ade informaciÃ³n extra o sugerencias.
        const { intencion, confianza, respuesta } = llmResult;
        console.log('ğŸ¯ Generando respuesta contextual para:', intencion);

        let enrichedResponse = respuesta;
        // La lÃ³gica de enriquecimiento de cursos ahora la maneja Gemini con Function Calling.

        return {
            intencion,
            confianza: confianza || 0.85,
            respuesta: enrichedResponse,
            sugerencias: await this.generateChatSuggestions(intencion, llmResult)
        };
    }

    // findRelevantCourses ya no es necesario aquÃ­, la lÃ³gica de bÃºsqueda de cursos
    // se maneja directamente en mlService a travÃ©s de la herramienta getCourseDetails
    // que llama a CourseRepository.

    async generateChatSuggestions(intencion, llmResult) {
        // Si el LLM ya proveyÃ³ sugerencias, podrÃ­amos usarlas.
        if (llmResult.sugerencias && llmResult.sugerencias.length > 0) {
            return llmResult.sugerencias;
        }

        // Si no, usamos las sugerencias predefinidas como fallback.
        const predefinedSuggestions = {
            'consulta_horario': [
                "Â¿Horarios de teorÃ­a o laboratorio?",
                "Â¿De quÃ© curso especÃ­fico?"
            ],
            'solicitar_material': [
                "Material de 'ProgramaciÃ³n I'",
                "Â¿Buscas PDFs o videos?"
            ],
            'duda_teorica': [
                "ExplÃ­came 'quÃ© es una API'",
                "Â¿Necesitas ejemplos prÃ¡cticos?"
            ],
            'consulta_evaluacion': [
                "Â¿Examen parcial o final?",
                "Â¿Fechas o contenidos?"
            ],
            'consulta_administrativa': [
                "InformaciÃ³n sobre matrÃ­cula",
                "Â¿Horarios de atenciÃ³n?"
            ]
        };
        return predefinedSuggestions[intencion] || ["Â¿En quÃ© mÃ¡s puedo ayudarte?", "Â¿Necesitas informaciÃ³n de otro curso?"];
    }

    async trainModel(req, res) {
        try {
            console.log('ğŸ¯ Solicitado re-entrenamiento del modelo...');
            if (!this.mlService) {
                throw new Error('Servicio ML no disponible');
            }
            const result = await this.mlService.trainModel();
            res.json(result);
        } catch (error) {
            console.error('âŒ Error entrenando modelo:', error);
            res.status(500).json({
                error: 'Error entrenando el modelo',
                detalles: error.message
            });
        }
    }
}

module.exports = ChatController; // âœ… CORRECCIÃ“N: Exportar la clase, no la instancia.