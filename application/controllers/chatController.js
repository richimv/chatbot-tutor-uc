const MLService = require('../../domain/services/mlService');
const AnalyticsService = require('../../domain/services/analyticsService');
const KnowledgeBaseRepository = require('../../domain/repositories/knowledgeBaseRepository');
const CourseRepository = require('../../domain/repositories/courseRepository');
const CareerRepository = require('../../domain/repositories/careerRepository');
// ‚úÖ FASE II: Importar el nuevo servicio de chat para manejar el historial.
const ChatService = require('../../domain/services/chatService');

class ChatController {
    constructor(chatService, analyticsService) {
        console.log('üîÑ Inicializando ChatController...');
        this.mlService = MLService;
        this.analyticsService = analyticsService;
        this.knowledgeBaseRepo = new KnowledgeBaseRepository();
        this.chatService = chatService;
        console.log('‚úÖ ChatController inicializado correctamente');

        // Bindeo expl√≠cito para mantener el contexto
        this.processMessage = this.processMessage.bind(this);
        this.trainModel = this.trainModel.bind(this);
        // ‚úÖ FASE II: Bindeo de los nuevos m√©todos para el historial.
        this.getUserConversations = this.getUserConversations.bind(this);
        this.getConversationMessages = this.getConversationMessages.bind(this);
        this.updateConversationTitle = this.updateConversationTitle.bind(this); // ‚úÖ MEJORA
        this.deleteConversation = this.deleteConversation.bind(this); // ‚úÖ MEJORA
    }

    /**
     * Procesa un mensaje del usuario, lo clasifica, obtiene una respuesta de la IA
     * y guarda toda la interacci√≥n en la base de datos.
     */
    async processMessage(req, res) {
        try {
            console.log('üí¨ ChatController.processMessage: this context:', {
                hasMlService: !!this.mlService,
                hasAnalyticsService: !!this.analyticsService,
            });

            // ‚úÖ FASE II: Extraer datos del request.
            const { message } = req.body;
            let { conversationId } = req.body; // 'let' porque puede ser creado.
            const userId = req.user.id; // Obtenido del token JWT.

            if (!message || message.trim() === '') {
                return res.status(400).json({ error: 'El mensaje no puede estar vac√≠o' });
            }

            console.log('üí¨ Procesando mensaje:', message);

            if (!this.mlService) {
                console.error('‚ùå ERROR CR√çTICO: mlService no est√° disponible');
                throw new Error('Servicio ML no disponible');
            }

            if (!this.analyticsService) {
                console.error('‚ùå ERROR CR√çTICO: analyticsService no est√° disponible');
            }

            // --- ‚úÖ FASE II: L√ìGICA DE PERSISTENCIA DEL CHAT ---
            // 1. Si es un mensaje nuevo, crear la conversaci√≥n en la BD.
            if (!conversationId) {
                const title = message.substring(0, 50) + (message.length > 50 ? '...' : '');
                const newConversation = await this.chatService.chatRepository.createConversation(userId, title);
                conversationId = newConversation.id;
            }

            // 2. Guardar el mensaje del usuario en la BD.
            await this.chatService.chatRepository.addMessage(conversationId, 'user', message);

            // 3. Obtener el historial COMPLETO desde la BD para dar contexto a la IA.
            const conversationHistory = await this.chatService.chatRepository.getMessagesByConversationId(conversationId, userId);

            // --- L√ìGICA ORIGINAL DE IA (MODIFICADA PARA USAR EL HISTORIAL DE LA BD) ---
            let classification;
            try {
                const loadedKBSet = await this.knowledgeBaseRepo.load();

                console.log('ü§ñ Intentando generar respuesta con LLM...');
                // Se pasa el historial obtenido de la base de datos.
                classification = await this.mlService.classifyIntent(message, conversationHistory, {
                    knowledgeBaseRepo: this.knowledgeBaseRepo,
                    courseRepo: new CourseRepository(),
                    careerRepo: new CareerRepository(),
                    knowledgeBaseSet: loadedKBSet
                });
                console.log('‚úÖ Respuesta de LLM recibida:', classification);
            } catch (mlError) {
                console.error('‚ùå ERROR CR√çTICO llamando a mlService:', mlError);
                // Si el servicio de ML falla por completo, devolvemos un error 500.
                return res.status(500).json({ error: 'El servicio de IA no est√° disponible' });
            }

            const response = await this.enrichResponse(message, classification);

            // 4. Guardar la respuesta del bot en la BD.
            const botMessage = await this.chatService.chatRepository.addMessage(conversationId, 'bot', response.respuesta);

            // 5. REGISTRAR EN ANALYTICS (L√≥gica original)
            if (this.analyticsService) {
                // ‚úÖ REFACTOR: Usar clasificaci√≥n centralizada basada en CONTENIDO
                const isEducational = this.analyticsService.isQueryEducational(message);

                await this.analyticsService.recordSearchWithIntent(
                    message,
                    [], // No hay "resultados" directos en una conversaci√≥n de chat
                    isEducational,
                    userId, 'chatbot' // ‚úÖ MEJORA: Especificar que la fuente es el chatbot.
                );
            }

            console.log('‚úÖ Respuesta generada exitosamente');

            res.json({
                ...response,
                // Devolver siempre el ID de la conversaci√≥n para que el frontend pueda continuarla.
                conversationId: conversationId,
                // ‚úÖ NUEVO: Devolver el ID del mensaje del bot para el feedback.
                messageId: botMessage.id,
                timestamp: new Date().toISOString()
            });

        } catch (error) {
            console.error('‚ùå Error en ChatController.processMessage:', error);
            res.status(500).json({
                error: 'Error al procesar el mensaje',
                respuesta: 'Lo siento, hubo un error al procesar tu mensaje. Por favor, intenta nuevamente.'
            });
        }
    }

    /**
     * Obtiene la lista de todas las conversaciones de un usuario.
     */
    async getUserConversations(req, res) {
        try {
            const userId = req.user.id;
            const conversations = await this.chatService.getConversations(userId);
            res.json(conversations);
        } catch (error) {
            console.error('‚ùå Error obteniendo conversaciones:', error);
            res.status(500).json({ error: 'Error al obtener las conversaciones.' });
        }
    }

    /**
     * Obtiene todos los mensajes de una conversaci√≥n espec√≠fica.
     */
    async getConversationMessages(req, res) {
        try {
            const userId = req.user.id;
            const conversationId = parseInt(req.params.id, 10);
            const messages = await this.chatService.getMessages(conversationId, userId);
            res.json(messages);
        } catch (error) {
            console.error('‚ùå Error obteniendo mensajes:', error);
            res.status(500).json({ error: 'Error al obtener los mensajes de la conversaci√≥n.' });
        }
    }

    /**
     * Actualiza el t√≠tulo de una conversaci√≥n.
     */
    async updateConversationTitle(req, res) {
        try {
            const userId = req.user.id;
            const conversationId = parseInt(req.params.id, 10);
            const { title } = req.body;

            if (!title || title.trim() === '') {
                return res.status(400).json({ error: 'El t√≠tulo no puede estar vac√≠o.' });
            }

            const updatedConversation = await this.chatService.updateConversationTitle(conversationId, title, userId);
            res.json(updatedConversation);
        } catch (error) {
            console.error('‚ùå Error actualizando t√≠tulo de conversaci√≥n:', error);
            res.status(500).json({ error: 'Error al actualizar el t√≠tulo.' });
        }
    }

    /**
     * Elimina una conversaci√≥n.
     */
    async deleteConversation(req, res) {
        try {
            const userId = req.user.id;
            const conversationId = parseInt(req.params.id, 10);

            const wasDeleted = await this.chatService.deleteConversation(conversationId, userId);

            if (wasDeleted) {
                res.status(204).send(); // No Content
            } else {
                // Esto puede pasar si el usuario intenta borrar un chat que no es suyo o no existe.
                res.status(404).json({ error: 'Conversaci√≥n no encontrada o no tienes permiso para eliminarla.' });
            }
        } catch (error) {
            console.error('‚ùå Error eliminando conversaci√≥n:', error);
            res.status(500).json({ error: 'Error al eliminar la conversaci√≥n.' });
        }
    }

    async enrichResponse(userMessage, llmResult) {
        // La respuesta principal ya viene del LLM.
        // Esta funci√≥n ahora solo a√±ade informaci√≥n extra o sugerencias.
        const { intencion, confianza, respuesta } = llmResult;
        console.log('üéØ Generando respuesta contextual para:', intencion);

        let enrichedResponse = respuesta;
        // La l√≥gica de enriquecimiento de cursos ahora la maneja Gemini con Function Calling.

        return {
            intencion,
            confianza: confianza || 0.85,
            respuesta: enrichedResponse,
            sugerencias: await this.generateChatSuggestions(intencion, llmResult)
        };
    }

    // findRelevantCourses ya no es necesario aqu√≠, la l√≥gica de b√∫squeda de cursos
    // se maneja directamente en mlService a trav√©s de la herramienta getCourseDetails
    // que llama a CourseRepository.

    async generateChatSuggestions(intencion, llmResult) {
        // Si el LLM ya provey√≥ sugerencias, podr√≠amos usarlas.
        if (llmResult.sugerencias && llmResult.sugerencias.length > 0) {
            return llmResult.sugerencias;
        }

        // Si no, usamos las sugerencias predefinidas como fallback.
        // Si no, usamos las sugerencias predefinidas como fallback.
        // ‚úÖ MEJORA: Sugerencias centradas en el usuario ("Yo quiero...") en lugar de preguntas del bot.
        // ‚úÖ MEJORA: Sugerencias centradas en el usuario ("Yo quiero...") 
        const predefinedSuggestions = {
            'solicitar_material': [
                "Ver libros del curso",
                "Buscar papers clave"
            ],
            'duda_teorica': [
                "Dame ejemplos",
                "¬øQu√© libros hablan de esto?"
            ],
            'consulta_evaluacion': [
                "¬øQu√© temas entran?",
                "Ver fechas importantes"
            ],
            'consulta_administrativa': [
                "Ver fechas de matr√≠cula",
                "Contactar soporte"
            ]
        };
        // Fallback general m√°s √∫til y seguro
        return predefinedSuggestions[intencion] || [
            "Buscar cursos",
            "Ver libros de Anatom√≠a",
            "Expl√≠came un tema"
        ];
    }

    async trainModel(req, res) {
        try {
            console.log('üéØ Solicitado re-entrenamiento del modelo...');
            if (!this.mlService) {
                throw new Error('Servicio ML no disponible');
            }
            const result = await this.mlService.trainModel();
            res.json(result);
        } catch (error) {
            console.error('‚ùå Error entrenando modelo:', error);
            res.status(500).json({
                error: 'Error entrenando el modelo',
                detalles: error.message
            });
        }
    }
}

module.exports = ChatController; // ‚úÖ CORRECCI√ìN: Exportar la clase, no la instancia.